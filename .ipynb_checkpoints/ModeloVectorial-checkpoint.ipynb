{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c23cb6f-d9bf-4a9f-895c-70fe9e1738db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "def calcular_frecuencias(documentos):\n",
    "    vocabulario = set()\n",
    "    frecuencias = []\n",
    "\n",
    "    for doc in documentos:\n",
    "        tokens = doc.lower().split()\n",
    "        vocabulario.update(tokens)\n",
    "        frecuencias.append(Counter(tokens))\n",
    "    \n",
    "    return list(vocabulario), frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecded689-ff46-4b36-a6d3-9be572982eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_matriz(documentos, vocabulario, frecuencias):\n",
    "    matriz = np.zeros((len(documentos), len(vocabulario)))\n",
    "\n",
    "    for i, freq in enumerate(frecuencias):\n",
    "        for j, palabra in enumerate(vocabulario):\n",
    "            matriz[i][j] = freq.get(palabra, 0)\n",
    "    \n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1c9b6b-1db0-4321-98c1-618fbba751c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similitud_coseno(v1, v2):\n",
    "    numerador = np.dot(v1, v2)\n",
    "    denominador = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    return numerador / denominador if denominador != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df5b1b4-eaf3-4a37-bc73-3edf6a9aa1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_vectorial(documentos, consulta):\n",
    "    corpus = documentos + [consulta]\n",
    "    vocabulario, frecuencias = calcular_frecuencias(corpus)\n",
    "    matriz_terminos = construir_matriz(corpus, vocabulario, frecuencias)\n",
    "    vector_consulta = matriz_terminos[-1]\n",
    "    matriz_documentos = matriz_terminos[:-1]\n",
    "    similitudes = [similitud_coseno(vector_consulta, doc) for doc in matriz_documentos]\n",
    "    \n",
    "    return similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5593c5cb-2483-481c-94aa-bef827013020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud entre la consulta y cada documento:\n",
      "Documento 1: 0.3015\n",
      "Documento 2: 0.3333\n",
      "Documento 3: 0.3536\n",
      "Documento 4: 0.3333\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    documentos = [\n",
    "        \"La CocaCola es una bebida muy popular en todo el mundo.\",\n",
    "        \"Pepsi y CocaCola son grandes competidores en la industria.\",\n",
    "        \"Me encanta tomar CocaCola con hielo y limón.\",\n",
    "        \"La CocaCola Zero tiene un sabor diferente al clásico.\"\n",
    "    ]\n",
    "    \n",
    "    consulta = \"CocaCola\"\n",
    "    resultado = modelo_vectorial(documentos, consulta)\n",
    "\n",
    "    print(\"Similitud entre la consulta y cada documento:\")\n",
    "    for i, similitud in enumerate(resultado):\n",
    "        print(f\"Documento {i+1}: {similitud:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbc891-e8dd-46a9-9d14-00248892766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_texto_de_url(url):\n",
    "    \"\"\"\n",
    "    Obtiene el texto de una página web a partir de la URL usando regex.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Verifica si la solicitud fue exitosa\n",
    "        \n",
    "        # Extraer el contenido de la página usando una expresión regular simple\n",
    "        texto = re.sub('<[^>]*>', '', response.text)  # Elimina todas las etiquetas HTML\n",
    "        texto = ' '.join(texto.split())  # Elimina múltiples espacios\n",
    "        \n",
    "        return texto\n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener el texto de la URL {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # URLs de ejemplo\n",
    "    urls = [\n",
    "        \"https://es.wikipedia.org/wiki/Coca-Cola\",\n",
    "        \"https://www.pepsi.com\",\n",
    "        \"https://www.coca-cola.com\",\n",
    "        \"https://www.bbc.com\"\n",
    "    ]\n",
    "\n",
    "    # Recuperar el texto de las URLs\n",
    "    documentos = [obtener_texto_de_url(url) for url in urls]\n",
    "\n",
    "    # Mostrar los primeros 500 caracteres de cada documento para verificar\n",
    "    for i, doc in enumerate(documentos):\n",
    "        print(f\"Documento {i+1}: {doc[:500]}...\")  # Muestra los primeros 500 caracteres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c3bf1c-1e39-451d-ac9c-e7f7a79de2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
